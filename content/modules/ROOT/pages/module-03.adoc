= Deploy a virtual machine from a bootc image

In this exercise, you will build a `qcow2` disk image from the bootc image and then launch
a virtual machine from it. `qcow2` is a standard file format used by the Linux virtualization system.

[#config]
== Create the config for building the virtual machine image

To deploy our bootc image as a host, we need to get the contents of the image onto a disk. While `bootc` 
handles those mechanics, the actual creation of a physical disk, virtual disk, or cloud image are handled 
by other standard tools. For example, Anaconda can be used with bootc images for physical or virtual hosts 
like you would today, but without the `%packages` block we use today. In this lab, we'll use the `bootc-image-builder` tool which can create various different disk image types and call `bootc` to deploy the image contents.

You may have noticed the bootc image we've created does not include any login credentials. Not a 
typical concern for an application container, but as a host we will very likely need to interact
at some point.

Since we are defining an image to be shared by multiple hosts in multiple different environments,
users and authentication is likely to be handled at the deployment stage, not the build stage.

NOTE: There are cases where it may be useful for a user and credentials to be added to an image, 
as a 'break glass' emergency login for example.

To add a user during the conversion to a disk image, you need add the credentials to the config file used by `bootc-image-builder` to create the final disk image.

We'll generate a new ssh key for use during the lab

[source,bash,role="execute",subs=attributes+]
----
ssh-keygen -f ~/.ssh/id_rsa -N ""
----

You can view the public part like this:

[source,bash,role="execute",subs=attributes+]
----
cat ~/.ssh/id_rsa.pub
----

The output should look something like this (Example):

....
ssh-ed25519 AAAAC3NzaC1lZDI1NTE5AAAAIAuXnpoluye+KM+9tvIAdHf+F0IHh+K73tlcjEG8LJRB lab-user@hypervisor
....

You can now create a file called `config-qcow2.toml` with the following contents, replacing "SSHKEY" 
in the `key` field with the contents of `~/.ssh/id_rsa.pub` from your system:

[source,bash,role="execute",subs=attributes+]
----
nano config-qcow2.toml
----

[source,yaml,role="execute",subs=attributes+]
----
[[customizations.user]]
name = "{vm_user}"
password = "{vm_user_pass}"
groups = ["wheel"]
key = "SSHKEY"
----

This configuration blueprint creates a user in the resulting virtual machine with the login `{vm_user}`, the password `{vm_user_pass}` and the ssh key of the user on the lab host.

[#create]
== Create the disk image

First, you want to make sure the bootc image is available to the local registry:

[source,bash,role="execute",subs=attributes+]
----
skopeo inspect docker://{registry_hostname}/httpd | jq '.Digest'
----
....
"sha256:655721ff613ee766a4126cb5e0d5ae81598e1b0c3bcf7017c36c4d72cb092fe9"
....

To convert from an OCI image to a disk image, we have a special version of image builder that has support for `bootc`. This `bootc-image-builder` itself runs as a container, and as a result needs additional capabilities and to be run as `root`. As `bootc-image-builder` accesses local storage to find the source image, we will need to copy our image from user storage to system storage. The `podman image scp` command can do this for us, as well as copying to various different targets. When executed with a source but without a destination as below, the default is local system storage.

[source,bash,role="execute",subs=attributes+]
----
podman image scp lab-user@localhost::{registry_hostname}/httpd
----

Try to generate the image now:

NOTE: This could take 2+ minutes to complete.

[source,bash,role="execute",subs=attributes+]
----
sudo podman run --rm --privileged \
  --security-opt label=type:unconfined_t \
  --volume .:/output \
  --volume ./config-qcow2.toml:/config.toml \
  --volume /var/lib/containers/storage:/var/lib/containers/storage \
  registry.redhat.io/rhel9/bootc-image-builder:latest \
  --type qcow2 \
  {registry_hostname}/httpd
----

A brief explanation of the arguments used for `podman` and `bootc-image-builder`:

  * `--rm` -> do not keep the build container after execution finishes
  * `--privileged` -> add capabilities required to build the image
  * `--volume` -> podman will map these local directories or files to the container
  * `registry.redhat.io/rhel9/bootc-image-builder:latest` -> the image builder container image

After the image builder version, these arguments passed to `bootc-image-builder`:

  * `--type qcow2` -> the type of image to build
  * `{registry_hostname}/httpd` -> the bootc image we are unpacking into the qcow2 disk

Once this completes, you will find the image is the `qcow2/` directory:

[source,bash,role="execute",subs=attributes+]
----
ls -lah qcow2/disk.qcow2
----

The output should be similar to:

....
-rw-r--r--. 1 root root 945M May  2 06:10 qcow2/disk.qcow2
....

[#create-vm]
== Create the virtual machine

Since we provided the QCOW2 type to `bootc-image-builder`, the resulting disk image is complete and ready to run without additional installation or other steps. We can copy the image to the standard storage pool location for KVM.

[source,bash,role="execute",subs=attributes+]
----
sudo cp qcow2/disk.qcow2 /var/lib/libvirt/images/qcow-vm.qcow2
----

The creation of KVM virtual machines is out of scope for this lab, but the core of the `virt-install` command used is `--import` which skips the install process and creates the VM based on the provided disk image. 

[source,bash,role="execute",subs=attributes+]
----
virt-install --connect qemu:///system \
  --name qcow \
  --disk /var/lib/libvirt/images/qcow-vm.qcow2 \
  --import \
  --memory 4096 \
  --graphics none \
  --osinfo rhel9-unknown \
  --noautoconsole \
  --noreboot
----

We can now start our new bootc virtual machine.

[source,bash,role="execute",subs=attributes+]
----
virsh --connect qemu:///system start qcow
----

Check to make sure the virtual machine running:

[source,bash,role="execute",subs=attributes+]
----
virsh --connect qemu:///system list
----
....
 Id   Name                State
------------------------------------
 1    qcow                running
....

[#test]
== Test and login to the virtual machine

Congratulations, you are running a bootc virtual machine!  Now that the virtual machine is up 
and running, you can see if the webserver behaves as expected.

[source,bash,role="execute",subs=attributes+]
----
curl http://qcow-vm
----

And the results should be the "Hello Red Hat" string defined in the index.html.

You can now login to the virtual machine.

[source,bash,role="execute",subs=attributes+]
----
ssh {vm_user}@qcow-vm
----

NOTE: If the ssh key is not automatically picked up, use the password defined in the config file at the beginning of this lab (by default `{vm_user_pass}`). 
This is also the password to use when prompted by `sudo`.

Once you have logged in, you can inspect the bootc status.

[source,bash,role="execute",subs=attributes+]
----
sudo bootc status
----

The output should look similar to this:

[source,yaml]
----
apiVersion: org.containers.bootc/v1alpha1
kind: BootcHost
metadata:
  name: host
spec:
  image:
    image: summit.registry/lb1506:bootc
    transport: registry
  bootOrder: default
status:
  staged: null
  booted: <1>
    image:
      image:
        image: summit.registry/lb1506:bootc
        transport: registry
      version: 9.20240501.0
      timestamp: null
      imageDigest: sha256:0a3daed6e31c2f2917e17ea994059e1aaee0481fe16836c118c5e1d10a87365c
    cachedUpdate: null
    incompatible: false
    pinned: false
    ostree:
      checksum: 008e3bef805f25224f591240627bea2a06ce12b25494836c2dab7d1b0a1691a8
      deploySerial: 0
  rollback: null
  rollbackQueued: false
  type: bootcHost
----

From the output of `bootc status`, find the block that starts with `booted`. 

<1> This block provides information about the image in use. You can see that image is listed as `summit.registry/lb1506:bootc`.

You can explore the virtual machine before moving on to the next section:

  * `systemctl status httpd` -> see the `httpd` service we have enabled in the Containerfile
  * `cat /var/www/html/index.html` -> see the index.html file we have created in the Containerfile

Our services are running, but how can we tell that we are on system and not running a container? First, `bootc` can tell you directly if it's being run 
on an image mode host or not in the `bootc status` output. It will be all `null` values if run on a non-bootc enabled host. 

For other ways, we can look at how the system was started and some of the characteristics that will change, like SELinux context.

Let's look at kernel command line as well as PID1 in the `/proc` filesystem and see what runtime info we have.

[source,bash]
----
 cat /proc/cmdline # <1> 
 cat /proc/1/cgroup # <2> 
 cat /proc/1/attr/current # <3>
----

We can see in the kernel command line some clear ties to an `ostree` partition, and our PID1 details shows systemd running with init scope from 
the cgroup hierarchy and SELinux context. We'll look at the container output in a later exercise, but the SELinux context would differ.

<1> `BOOT_IMAGE=(hd0,gpt3)/boot/ostree/default-6fe9dddacaf5c3232ba2332010aa7442e0a6d0e3f455b7572b047cc2284c3f2f/vmlinuz-5.14.0-427.26.1.el9_4.x86_64 root=UUID=5425bac2-bfc2-457d-93f8-ae7d3bf14d6d rw boot=UUID=9b9c7b0a-61c6-4a66-ade5-8c6690f1efa7 rw console=tty0 console=ttyS0 ostree=/ostree/boot.1/default/6fe9dddacaf5c3232ba2332010aa7442e0a6d0e3f455b7572b047cc2284c3f2f/0`
<2> `0::/init.scope`
<3> `system_u:system_r:init_t:s0`


Before proceeding, make sure you have logged out of the virtual machine:

[source,bash,role="execute",subs=attributes+]
----
logout
----

The prompt should read `[lab-user@hypervisor rh-summit-2024-lb1506]$` before continuing.
