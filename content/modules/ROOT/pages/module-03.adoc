= Deploy a virtual machine with bootc image

In this lab, you will build a `qcow2` disk image from the bootc image and then launch
a virtual machine from it. `qcow2` is a standard file format used by the Linux virtualization system.

NOTE: This exercise includes both a make command and the commands executed by that make target. You do not need to 
execute both.

[#config]
== Create the config for building the virtual machine image

To deploy our bootc image as a host, we need to get the contents of the image onto a disk. While `bootc` 
handles those mechanics, the actual creation of a phyiscal disk, virtual disk, or cloud image are handled 
by other standard tools. For example, Anaconda can be used with bootc images for phyiscal or virtual hosts 
like you would today, but without the `%packages` block we use today. In this lab, we'll use the `bootc-image-builder` 
tool which can create various different disk image types and call `bootc` to deploy the image contents.

You may have noticed the bootc image we've created does not include any login credentials. Not a 
typical concern for an application container, but as a host we will very likely need to interact
at some point.

Since we are defining an image to be shared by multiple hosts in multiple different environments,
users and authentication is likely to be handled at the deployment stage, not the build stage.

NOTE: There are cases where it may be useful for a user and credentials to be added to an image, 
as a 'break glass' emergency login for example.

To add a user during the conversion to a disk image, you need to create a JSON file with the credentials.
This config file will be used by `bootc-image-builder` to customize the final disk image.

A ssh key has been generated in the Setup section of this lab. You can view the public part like this:

[source,bash]
----
cat ~/.ssh/id_rsa.pub
----

The output should look something like this (Example):

....
ssh-ed25519 AAAAC3NzaC1lZDI1NTE5AAAAIAuXnpoluye+KM+9tvIAdHf+F0IHh+K73tlcjEG8LJRB lab-user@hypervisor
....

You can now create a file called `config-qcow2.json` with the following contents, replacing "SSHKEY" 
in the `key` field with the contents of `~/.ssh/id_rsa.pub` from your system:

[source,bash]
----
nano config-qcow2.json
----

[source,json]
----
{
  "blueprint": {
    "customizations": {
      "user": [
        {
          "name": "lab-user",
          "password": "lb1506",
          "key": "SSHKEY",
          "groups": [
            "wheel"
          ]
        }
      ]
    }
  }
}
----

This configuration blueprint creates a user in the resulting virtual machine with the login `lab-user`, the password `lb1506` and the 
ssh key of the user on the lab host.

NOTE: For your convenience, a config file has already been generated with the ssh key for your lab host in `config/config-qcow2.json` so
you can just use that with `cp config/config-qcow2.json config-qcow2.json`.

[#create]
== Create the disk image

First, you want to make sure the bootc image is available to the local registry:

[source,bash]
----
skopeo inspect docker://summit.registry/lb1506:bootc | jq '.Digest'
----
....
"sha256:655721ff613ee766a4126cb5e0d5ae81598e1b0c3bcf7017c36c4d72cb092fe9"
....

To convert from an OCI image to a disk image, we have a special version of image builder that has support for `bootc`. This 
`bootc-image-builder` itself runs as a container, and as a result needs additional capabilities and to be run as `root`.

Try to generate the image now:

NOTE: This could take 2+ minutes to complete.
[source,bash]
----
sudo podman run --rm --privileged \
        --volume .:/output \
        --volume ./config-qcow2.json:/config.json \
        registry.redhat.io/rhel9/bootc-image-builder:latest \
        --type qcow2 --config /config.json \
        --tls-verify=false \
        summit.registry/lb1506:bootc
----

A brief explanation of the arguments used for `podman` and `bootc-image-buider`:

  * `--rm` -> do not keep the build container after execution finishes
  * `--privileged` -> add capabilities required to build the image
  * `--volume` -> podman will map these local directories or files to the container
  * `registry.redhat.io/rhel9/bootc-image-builder:latest` -> the image builder container image

From here, these arguments passed to `bootc-image-builder`

  * `--type qcow2` -> the type of image to build
  * `--config /config.json` -> the json configuration file used; please note this is relative to the container volume we added
  * `--tls-verify=false` -> the registry we are running is local and it has self signed certificates; this flag would not be needed with `quay.io` for example
  * `summit.registry/lb1506:bootc` -> the bootc image we are unpacking into the qcow2 disk

Once this completes, you will find the image is the `qcow2/` directory:

NOTE: For your convenience, this part of the exercise is automated by using the `make qcow CONTAINER=summit.registry/lb1506:bootc` command.

[source,bash]
----
ls -lah qcow2/disk.qcow2
----

The output should be similar to:

....
-rw-r--r--. 1 root root 945M May  2 06:10 qcow2/disk.qcow2
....

[#create-vm]
== Create the virtual machine

The creation of virtual machines is out of scope for this lab, so we have provided a convenience command in the Makeile.
We've detailed the commnds being run so you can follow along with what is happening. If you like, feel free to run the 
commands on your own instead of using the `make` target. The core of the `virt-install` command used is `--import` which 
skips the install process and creates the VM based on the provided disk image.

[source,bash]
----
make vm-qcow
----

*For reference*, commands executed in the Makefile and displayed in the terminal are:

[source,bash]
----
sudo cp qcow2/disk.qcow2 /var/lib/libvirt/images/summit/qcow-vm.qcow2
virt-install --connect qemu:///system \
                --name qcow \
                --disk /var/lib/libvirt/images/summit/qcow-vm.qcow2 \
                --import \
                --network "network=summit-network,mac=de:ad:be:ef:01:03" \
                --memory 4096 \
                --graphics none \
                --osinfo rhel9-unknown \
                --noautoconsole \
                --noreboot
virsh --connect qemu:///system start qcow
----

If `make vm-qcow` was successful, you should see the final line of output like this:

....
Domain 'qcow' started
....

Check to make sure the virtual machine running:

[source,bash]
----
virsh --connect qemu:///system list
----
....
 Id   Name                State
------------------------------------
 1    qcow                running
....

[#test]
== Test and login to the virtual machine

Congratulations, you are running a bootc virtual machine!  Now that the virtual machine is up 
and running, you can see if the webserver behaves as expected.

[source,bash]
----
curl http://qcow-vm
----

And the results should be the "Hello Red Hat" string defined in the index.html.

You can now login to the virtual machine.

[source,bash]
----
ssh lab-user@qcow-vm
----

NOTE: If the ssh key is not automatically picked up, use the password defined in the JSON file at the beginning of this lab (by default `lb1506`). 
This is also the password to use when prompted by `sudo`.

Once you have logged in, you can inspect the bootc status.

[source,bash]
----
sudo bootc status
----

The output should look similar to this:

[source,yaml]
----
apiVersion: org.containers.bootc/v1alpha1
kind: BootcHost
metadata:
  name: host
spec:
  image:
    image: summit.registry/lb1506:bootc
    transport: registry
  bootOrder: default
status:
  staged: null
  booted: <1>
    image:
      image:
        image: summit.registry/lb1506:bootc
        transport: registry
      version: 9.20240501.0
      timestamp: null
      imageDigest: sha256:0a3daed6e31c2f2917e17ea994059e1aaee0481fe16836c118c5e1d10a87365c
    cachedUpdate: null
    incompatible: false
    pinned: false
    ostree:
      checksum: 008e3bef805f25224f591240627bea2a06ce12b25494836c2dab7d1b0a1691a8
      deploySerial: 0
  rollback: null
  rollbackQueued: false
  type: bootcHost
----

From the output of `bootc status`, find the block that starts with `booted`. 

<1> This block provides information about the image in use. You can see that image is listed as `summit.registry/lb1506:bootc`.

You can explore the virtual machine before moving on to the next section:

  * `systemctl status httpd` -> see the `httpd` service we have enabled in the Containerfile
  * `cat /var/www/html/index.html` -> see the index.html file we have created in the Containerfile

Our services are running, but how can we tell that we are on system and not running a container? First, `bootc` can tell you directly if it's being run 
on an image mode host or not in the `bootc status` output. It will be all `null` values if run on a non-bootc enabled host. 

For other ways, we can look at how the system was started and some of the characteristics that will change, like SELinux context.

Let's look at kernel command line as well as PID1 in the `/proc` filesystem and see what runtime info we have.

[source,bash]
----
 cat /proc/cmdline # <1> 
 cat /proc/1/cgroup # <2> 
 cat /proc/1/attr/current # <3>
----

We can see in the kernel command line some clear ties to an `ostree` partition, and our PID1 details shows systemd running with init scope from 
the cgroup hierarchy and SELinux context. We'll look at the container output in a later exercise, but the SELinux context would differ.

<1> `BOOT_IMAGE=(hd0,gpt3)/boot/ostree/default-6fe9dddacaf5c3232ba2332010aa7442e0a6d0e3f455b7572b047cc2284c3f2f/vmlinuz-5.14.0-427.26.1.el9_4.x86_64 root=UUID=5425bac2-bfc2-457d-93f8-ae7d3bf14d6d rw boot=UUID=9b9c7b0a-61c6-4a66-ade5-8c6690f1efa7 rw console=tty0 console=ttyS0 ostree=/ostree/boot.1/default/6fe9dddacaf5c3232ba2332010aa7442e0a6d0e3f455b7572b047cc2284c3f2f/0`
<2> `0::/init.scope`
<3> `system_u:system_r:init_t:s0`


Before proceeding, make sure you have logged out of the virtual machine:

[source,bash]
----
logout
----

The prompt should read `[lab-user@hypervisor rh-summit-2024-lb1506]$` before continuing.
